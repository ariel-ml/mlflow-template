name: DemoMLPipeline

# Use the system environment managed by Poetry
# mlflow run . --env-manager: local # or virtualenv
# or
# python_env: python_env.yaml
# or
# conda_env: conda.yaml
# or
# docker_env:
#    image:  mlflow-docker-example

entry_points:
  load:
    command: "python -m pipelines.etl.load_data"
  split:
    command: "python -m pipelines.etl.split"
  scale:
    command: "python -m pipelines.feature_eng.scale"
  train:
    parameters:
      estimators: {type: int, default: 100}  # Optional with a default value
      max-depth: {type: int, default: 5}  # Optional with a default value
    command: "python -m pipelines.train.train_manual --estimators {estimators} --max-depth {max-depth}"
